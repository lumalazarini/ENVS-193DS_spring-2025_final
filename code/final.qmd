---
title: "ENVS 193DS Final"
author: "Luma Lazarini"
date: "06/5/25"
format:
  html:
    toc: true # use this to display a table of contents
execute:
  message: false # use this to make sure messages don't show up
  warning: false # use this to make sure warnings don't show up
---

[Github repo link](https://github.com/lumalazarini/ENVS-193DS_spring-2025_final)

# Set up

```{r, warning=FALSE, message=FALSE}
library(tidyverse) # general use
library(here) # file/folder organization
library(ggeffects) # generating model predictions
library(gtsummary) # generating summary tables for models
library(gt)
library(janitor)
library(dplyr)
library(tidyr)
library(scales) # modifying axis labels
library(ggeffects) # getting model predictions
library(DHARMa)
library(MuMIn)

```

# 1. Research writing

## a. Transparent statistical methods

In part 1, they used a Pearson's correlation test, since the data is parametric, to describe how the two variables relate to each other. In part 2, they used a one-way ANOVA test to compare means across multiple groups.

## b. More information needed

One additional test my coworker should run for Part 2 is Tukey’s Honest Significant Difference (HSD) test, which allows for pairwise comparisons between nitrogen sources. This would show which specific sources (e.g., fertilizer vs. grasslands) have significantly different nitrogen loads, rather than just indicating that a difference exists overall.

They should also report descriptive statistics such as the effect size for each source group. These values provide important context about the magnitude differences between the different sources to allow the viewers to understand the variability within each source category.

## c. Suggestions for rewriting

We found a \[small/moderate/large\] relationship between distance from headwater and annual total nitrogen load in the San Joaquin River Delta, suggesting that location along the river may influence nitrogen accumulation. (Pearson correlation: r = \[correlation coefficient\], p = 0.03, α = \[significance level\])

We found a statistically significant difference in mean annual nitrogen load among the five nitrogen sources (one-way ANOVA, F = \[F-statistic\], df = \[degrees of freedom\], p = 0.02, α = \[significance level\]). On average, source A had the highest nitrogen load (mean, CI kg year⁻¹), while source B had the lowest. The effect size (η² = effect size) suggests a \[small/moderate/large\] impact of source type on nitrogen load.

# 2. Data visualization

```{r}
#reading in data
sst <- read_csv(here("data", "SST_update2023.csv"))
```

## a. Cleaning and summarizing

```{r}
#cleaning data
sst_clean <- sst |>
  clean_names() |> #clean column names
  mutate(
    year = year(date), #extract year from date in new column
    month = month(date, label = TRUE, abbr = TRUE)  # extract month in new column as abbreviated motnh name
  ) |> 
  # Group by year and month
  group_by(year, month) |> 
   summarise(
    mean_monthly_sst = mean(temp, na.rm = TRUE), # calculate mean sea surface temperature per group, ignoring missing values
    .groups = "drop") |>   # ungroup after summarising to avoid carrying grouping structure forward
  mutate(
    year = as.factor(year), # convert year to a factor (categorical variable)
    month = factor(month, levels = month.abb, ordered = TRUE))  # make month an ordered factor with levels in calendar order (Jan to Dec)


```

```{r}
# Show 5 random rows
slice_sample(sst_clean, n = 5)

```

```{r}
# Show structure
str(sst_clean)
  
```

## b. Visualize the data

```{r}
# Filter to only include 2018–2023
sst_subset <- sst_clean |> 
  filter(year %in% c("2018", "2019", "2020", "2021", "2022", "2023"))

# Create a color gradient from light to dark
ggplot(sst_subset, 
       aes(x = month, #month on the x axis
           y = mean_monthly_sst, #mean monthly sst on the y axis
           group = year, #group lines/points by year
           color = year)) + #color lines/points by year
  geom_line(size = 1) + #  # add lines connecting data points
  geom_point(size = 2) + # add points for each observation
# Define custom color scale from light blue to black with 6 shades (one for each year)
  scale_color_manual(values = scales::seq_gradient_pal("lightblue", "black", "Lab")
                     (seq(0, 1, length.out = 6))) +

   # Setting up graph labels
   labs(
    x = "Month",
    y = "Mean monthly sea surface temperature (°C)",
    color = "Year" #legend title of colors
  ) +
  theme_minimal(base_size = 12) + # use minimal theme with base font size 12
  theme(
    legend.position = c(0.1, .7), # legend inside the panel
    panel.border = element_rect(color = "black", fill = NA), # black panel border
    panel.background = element_rect(fill = "white"), # white background
    legend.background = element_rect(fill = "white", color = NA), #white background for legend
    panel.grid = element_blank() #removing grid lines
  )

```

# 3. Data analysis

```{r}
#reading in data
nest_boxes <- read_csv(here("data", "occdist.csv")) |> 
  clean_names() #cleaning column names

```

## a. Response variable

In this dataset, 1s mean that a swift parrot was the species in the nest boxes, while 0s mean that another species was occupying the nest boxes.

## b. Purpose of study

Swift parrots are the target species, which are at critically risk of extinction. The other two species, the Common Starlings and Tree Martins, are non-target species that may compete with Swift Parrots for nesting sites.

## c. Difference in “seasons”

These two years (2016 and 2019) are referred to as seasons because they represent Swift Parrot breeding years triggered by mast flowering events. They are different because in 2016, nest boxes were newly installed, while in 2019 the same boxes were reused to compare nest box occupancy across time and assess whether permanent nest boxes benefit Swift Parrots or attract non-target species.

## d. Table of models

| Model number | Season | Distance to f/e | Description                |
|:------------:|:------:|:---------------:|:---------------------------|
|      0       |   No   |       No        | Null model                 |
|      1       |  Yes   |       Yes       | Saturated model            |
|      2       |  Yes   |       No        | only season as predictor   |
|      3       |   No   |       Yes       | only distance as predictor |

## e. Run the models

```{r model-fitting}
## Model fitting

# model 0: null model
model0 <- glm(
  sp ~ 1, # formula: no predictors, just the intercept
  data = nest_boxes,# data frame
  family = "binomial" # binomial distribution for logistic regression
)

# model 1: all predictors (saturated model)
model1 <- glm(
  sp ~ season + edge_distance, # formula: season and edge distance as predictors
  data = nest_boxes,# data frame
  family = "binomial" # binomial distribution for logistic regression
)

# model 2: season only
model2 <- glm(
  sp ~ season, # formula: season as predictor
  data = nest_boxes,# data frame
  family = "binomial" # binomial distribution for logistic regression
)

# model 3: distance only
model3 <- glm(
  sp~ edge_distance,# formula: edge distance as predictor
  data = nest_boxes,# data frame
  family = "binomial" # binomial distribution for logistic regression
)
```

## f. Check the diagnostics

```{r model-diagnostics}
## Model diagnostics

# Set up a 2x2 plotting grid
par(mfrow = c(2, 2))

# Plot simulated residuals for each model
plot(simulateResiduals(fittedModel = model0))
plot(simulateResiduals(fittedModel = model1))
plot(simulateResiduals(fittedModel = model2))
plot(simulateResiduals(fittedModel = model3))
```

## g. Select the best model

```{r}
# Compare all models using AICc
AICc(model0,
     model1,
     model2,
     model3) |> 
  arrange(AICc)
```
The best model is Model 1, predicting the probability of Swift Parrot presence with season and edge_distance as predictors, as determined by Akaike’s Information Criterion (AIC).

```{r model-summary}
#summarize best model
summary(model1)

```

## h. Visualize the model predictions

```{r model-predictions}
model1_predictions <- ggpredict(
  model1, # model object
  terms = c("edge_distance [all]", "season") # predictors
) |> 
  # renaming the columns
  rename(edge_distance= x,
         season= group)


```

```{r final-figure}

# Set custom colors for each season
season_colors <- c("2016" = "magenta", "2019" = "blue")

# Plot with predictions and raw data
ggplot() +
  # Raw data points
  geom_jitter(data = nest_boxes, #original data frame
              aes(x = edge_distance, #distance from forest edge on x-axis
                  y = sp, #nest box occupancy (binary) on y-axis
                  color = factor(season)), # color points by season (as factor)
              alpha = 0.5, # make points semi-transparent
              width = 0,  # no horizontal jitter
              height = 0.05, # small vertical jitter to show overlapping points
              size = 1.2) + # set point size
  
  # Model predictions with confidence ribbon
  geom_ribbon(data = model1_predictions, # use predicted model data
              aes(x = edge_distance, # distance from forest edge on x-axis
                  ymin = conf.low,  # lower bound of 95% confidence interval
                  ymax = conf.high, # upper bound of 95% confidence interval
                  fill = season), # fill ribbon by season
              alpha = 0.3) +   # semi-transparent ribbons
# Model prediction lines
  geom_line(data = model1_predictions,# use predicted model data
            aes(x = edge_distance,# distance from forest edge on x-axis
                y = predicted, # y-axis: predicted probability
                color = season), # color lines by season
            size = 1.1) + # line thickness
  
  # Customize colors
  scale_color_manual(values = season_colors) +  # apply custom colors to points/lines
  scale_fill_manual(values = season_colors) + # apply custom colors to ribbon
  
# Axis plot and labels
  labs(
    x = "Distance to Forest Edge (meters)",
    y = "Swift Parrot Nest Box Occupancy Probability",
    title = "Model Predictions of Swift Parrot Occupancy"
  ) +
  
# Use a clean minimal theme
  theme_minimal() +
  theme(
    panel.grid = element_blank(), # remove gridlines
    plot.title = element_text(face = "bold", size = 14), #style plot title
    legend.title = element_blank() #remove legend title
  ) 
```

## i. Write a caption for your figure
Figure 1. This figure displays the predicted probability of Swift Parrot nest box occupancy as a function of distance from the forest edge. Results are shown separately for the 2016 (magenta) and 2019 (blue) seasons. Occupancy is coded as 1 when a Swift Parrot was present and 0 when either another species or no bird was present. The plot shows a decline in occupancy probability as distance from the forest edge increases. Additionally, overall occupancy was lower in 2019 than in 2016.
Data source: Stojanovic, Dejan et al. (2021). Do nest boxes breed the target species or its competitors? A case study of a critically endangered bird [Dataset]. Dryad. https://doi.org/10.5061/dryad.83bk3j9sb

## j. Calculate model predictions

```{r, warning=FALSE, message=FALSE}
mod_preds <- ggpredict(
  model1,
  terms = c("edge_distance [0:900]", "season")  # edge_distance from 0 to 900, for each season
)

mod_preds
```

## k. Interpret your results

The predicted probability of occupancy at the forest edge (0 m) is 0.48 in 2016 and 0.30 in 2019. Farther from the forest edge (900 m), the predicted probabilities drop to 0.12 in 2016 and 0.06 in 2019. This pattern shows that as distance from the forest edge increases, the probability of Swift Parrot occupancy decreases. Biologically, this can be explained by increased presence of Tree Martins closer to the forest edge, suggesting there may be competition between the two species for nest boxes. These findings are supported by the visualized model predictions in part h and the specific probability estimates calculated above (part j).

# 4. Affective and exploratory visualizations

## a. Comparing visualizations

The exploratory visualization I created in Homework 2 was a much more artistically-based piece. It was a symbolic drawing of a person melting into their phone screen while in class, meant to represent how distracting phones can be even in educational settings. To make it more representative of the data, in Homework 3, I transformed it into a graph of my class schedule, with bars showing my mean screen time for each day of the week.

A similarity that I see is that they are all on the creative side, something that I feel proud of. However, one is more artistic while the other is more data driven.

My results didn’t show a strong relationship between my two main variables, screen time and minutes in class. In my data visualization, Homework 3 made this lack of relationship more clearly visible, as I had a lot more data compared to Homework 2. The affective and exploratory visualizations were very different in how they illustrated the data.

In week 9, I received feedback from my peers suggesting I decrease the number of bar columns in my graph to just one mean value per day. I implemented this and thought it improved the visualization, making the relationship between days and class time much clearer. I also got feedback to turn my visualization into a digital format, which I was already planning to do, so that aligned with my own goals.

## b. Sharing your affective visualization

Attended section!
